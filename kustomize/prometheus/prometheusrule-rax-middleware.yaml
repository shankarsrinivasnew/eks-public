apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    app: kube-prometheus-stack
    release: prometheus
  name: rax-cw-middleware-monitoring
  namespace: prometheus
spec:
  groups:
    - name: MIDDLEWARE_MONITORING_RULES
      rules:
        - alert: scylla_db_node_count
          expr: count(up{job="ec2-discover-node-exporter",instance=~".*scylla.*"} == 1) < 3
          for: 15m
          labels:
            severity: CRITICAL
            priority: P4
            environment: "{{ AWS_ENVIRONMENT }}"
            monitoring: middleware
            rackspace: "true"
            hostname: "{{ $labels.instance }}"
            tsbci: AWS_ELZ
          annotations:
            summary: Scylla in {{ $labels.environment }} has less than 3 nodes.
        - alert: jvm_heap_size
          expr: (avg(jvm_memory_used_bytes{area="heap"} / jvm_memory_max_bytes{area="heap"}) by (instance)) * 100 > 95
          for: 15m
          labels:
            severity: CRITICAL
            priority: P4
            environment: "{{ AWS_ENVIRONMENT }}"
            monitoring: middleware
            rackspace: "true"
            hostname: "{{ $labels.pod }}"
            tsbci: AWS_ELZ
          annotations:
            summary: Application {{ $labels.service }} in {{ $labels.environment }} jvm heap size is over 95% for 15mins

        - alert: consul_up
          expr: consul_up < 1
          for: 15m
          labels:
            severity: CRITICAL
            priority: P4
            environment: "{{ AWS_ENVIRONMENT }}"
            monitoring: middleware
            rackspace: "true"
            hostname: "{{ $labels.instance }}"
            tsbci: AWS_ELZ
          annotations:
            summary: Application {{ $labels.service_name }} in {{ $labels.environment }} is down

        - alert: members_in_cluster
          expr: consul_serf_lan_members < 6 
          for: 15m
          labels:
            severity: CRITICAL
            priority: P4
            environment: "{{ AWS_ENVIRONMENT }}"
            monitoring: middleware
            rackspace: "true"
            hostname: "{{ $labels.instance }}"
            tsbci: AWS_ELZ
          annotations:
            summary: Application {{ $labels.service_name }} in {{ $labels.environment }} has less than 6 nodes

        - alert: unhealthy_consul_service
          expr: (consul_health_service_status{status="passing"}) < 1
          for: 15m
          labels:
            severity: WARNING
            priority: P4
            environment: "{{ AWS_ENVIRONMENT }}"
            monitoring: middleware
            rackspace: "true"
            hostname: "{{ $labels.instance }}"
            tsbci: AWS_ELZ
          annotations:
            summary: consul service {{ $labels.service_name }} in {{ $labels.environment }} is unhealthy

        - alert: unhealthy_node
          expr: consul_health_node_status{status!='passing'} > 0
          for: 15m
          labels:
            severity: CRITICAL
            priority: P4
            environment: "{{ AWS_ENVIRONMENT }}"
            monitoring: middleware
            rackspace: "true"
            hostname: "{{ $labels.instance }}"
            tsbci: AWS_ELZ
          annotations:
            summary: Consul node {{ $labels.node }} in {{ $labels.environment }} is unhealthy